# AIâ€‘toâ€‘AI Debate Platform â€“ PRD (HackathonÂ v0.1)

> **Timeâ€‘box**: 2Â hours total.  
> **Goal**: deliver a runnable Mastra workflow that lets two agents debate, an arbiter summarise, and outputs `report.md`.

---

## 1â€¯Â·â€¯Vision
Give users a **oneâ€‘click way to resolve disagreements** by delegating the argument to their personal AI agents. The system produces a clear, unbiased Markdown report showing agreements, disagreements, compromise, and a confidence score.

## 2â€¯Â·â€¯Target Users & Jobsâ€‘toâ€‘Beâ€‘Done
| Persona | JTBD | Pain Today |
|---------|------|-----------|
| Friends / Couples | "Settle an argument without hard feelings." | Emotional friction, bias |
| Coâ€‘founders | "Decide roadmap priorities quickly." | Endless meetings |
| VCs / PE analysts | "Validate conflicting claims during DD." | Manual expert calls |
| DAO members | "Find consensus on proposals." | Forum noise, voter apathy |

## 3â€¯Â·â€¯Value Proposition
- **Speed**Â â€“ <60â€¯s automated debate.
- **Impartiality**Â â€“ arbiter model applies rules & citations.
- **Transparency**Â â€“ full debate log + confidence metric.

## 4â€¯Â·â€¯Functional Requirements (MVP)
1. **Input Phase**  
   `claimA` & `claimB` (string) via CLI trigger.  
   Optional: `constraints` object (ignored for hackathon).
2. **Agent Briefing**  
   `AgentA` & `AgentB` instantiated with user claims.
3. **Debate Engine**  
   Two turnâ€‘based rounds (Aâ†’Bâ†’Aâ†’B). Each turn must:  
   â€“ reference opponentâ€™s last message  
   â€“ cite at least one fact (simple "[citation needed]" placeholder is OK).
4. **Arbiter Phase**  
   Generates Markdown summary containing:  
   *Areas of Agreement* / *Disagreement* / *Suggested Compromise* / *ConfidenceÂ 0â€‘100*.
5. **Output Phase**  
   Save to `report.md`; print path to console.

## 5â€¯Â·â€¯Nonâ€‘Functional Requirements
- **Local first** â€“ no extra cloud infra; run with `ts-node`.
- **Cheap** â€“ â‰¤â€¯3 OpenAI calls (gptâ€‘4oâ€‘mini) per run.
- **Deterministic** â€“ set `temperatureÂ 0.3`.
- **Readable** â€“ Markdown report uses headings & bold for sections.

## 6â€¯Â·â€¯Technical Design
**Stack**: MastraÂ (CoreÂ v0.13), TypeScriptÂ 5, OpenAIÂ SDK, dotenv.

```mermaid
flowchart TD
  A[CLI Trigger] -->|claimA / claimB| W[Mastra Workflow]
  subgraph Debate
    A1[AgentA] ---|rounds| B1[AgentB]
  end
  W --> J[Arbiter Agent]
  J --> R[report.md]
```

### Components
| File | Purpose |
|------|---------|
| `src/agents/debaters.ts` | FactoryÂ `makeDebater()` + singleton `arbiter` |
| `src/workflows/debate.workflow.ts` | Step graph: init â†’ A1 â†’ B1 â†’ judge |
| `src/run.ts` | CLI runner / dev entry |
| `report.md` | Generated output |

## 7â€¯Â·â€¯Data Schemas
```ts
// Trigger
{
  claimA: string,
  claimB: string
}

// judge output
interface Summary {
  agreement: string;
  disagreement: string;
  compromise: string;
  confidence: number; // 0â€‘100
}
```

## 8â€¯Â·â€¯Acceptance Criteria
- [ ] Running `npm start -- "Cats are better" "Dogs are better"` creates `report.md`.
- [ ] Report includes *all four* required sections.
- [ ] Mastra trace shows 4Â steps and completes <90â€¯s.

## 9â€¯Â·â€¯Development Plan (120Â min)
| Min | Task |
|-----|------|
| 0â€‘10 | Repo init, install deps, set `.env` |
| 10â€‘25 | Write agents file |
| 25â€‘55 | Build workflow + run test |
| 55â€‘70 | Polish prompts, add timestamp header |
| 70â€‘80 | README with run instructions & screenshot note |
| 80â€‘100 | Record 90â€‘sec Loom demo |
| 100â€‘115 | Fill hackathon form |
| 115â€‘120 | Buffer / coffee |

## 10â€¯Â·â€¯Future Extensions (Postâ€‘hackathon)
- Retrievalâ€‘augmented fact checks (WikipediaÂ RAG).
- Web UI wizard (Next.js + shadcn/ui).
- Multiâ€‘party (>2) debates with ranking.
- Stripeâ€metered API.
- Evaluation harness (GPTâ€‘Judge) for quality scoring.

## 11â€¯Â·â€¯Skeleton Code Snippet
```ts
// src/run.ts
import { runWorkflow } from "@mastra/core";
import { debateWorkflow } from "./workflows/debate.workflow";

runWorkflow(debateWorkflow, {
  triggerData: {
    claimA: process.argv[2] ?? "Cats rule.",
    claimB: process.argv[3] ?? "Dogs drool."
  }
}).then(({ results }) => {
  const md = "# ResolveAI Demo\n\n" + results.judge.report;
  require("fs").writeFileSync("report.md", md);
  console.log("âœ…  report.md saved");
});
```

---
**Ready to vibeâ€‘code in Cursor ðŸŽ§** â€“ drop this `AI-Debate-PRD.md` in your repo, open it sideâ€‘byâ€‘side, and ask Cursor to generate each file stub. Good hacking! ðŸš€
